[INFO] Download dataset: MNIST
[INFO] Padronizando imagens de acordo com a lib utilizada em backend pelo Keras
[INFO] Tensorflow
[INFO] inicializando e otimizando a CNN...
[INFO] treinando a CNN...
Train on 60000 samples, validate on 10000 samples
Epoch 1/20
 - 20s - loss: 1.2984 - acc: 0.5849 - val_loss: 0.4175 - val_acc: 0.8706
Epoch 2/20
 - 20s - loss: 0.3105 - acc: 0.9071 - val_loss: 0.2555 - val_acc: 0.9243
Epoch 3/20
 - 19s - loss: 0.2165 - acc: 0.9349 - val_loss: 0.1735 - val_acc: 0.9480
Epoch 4/20
 - 21s - loss: 0.1715 - acc: 0.9487 - val_loss: 0.1541 - val_acc: 0.9511
Epoch 5/20
 - 21s - loss: 0.1456 - acc: 0.9560 - val_loss: 0.1260 - val_acc: 0.9608
Epoch 6/20
 - 19s - loss: 0.1269 - acc: 0.9614 - val_loss: 0.1133 - val_acc: 0.9654
Epoch 7/20
 - 20s - loss: 0.1123 - acc: 0.9658 - val_loss: 0.1030 - val_acc: 0.9681
Epoch 8/20
 - 21s - loss: 0.1030 - acc: 0.9682 - val_loss: 0.0909 - val_acc: 0.9721
Epoch 9/20
 - 20s - loss: 0.0941 - acc: 0.9713 - val_loss: 0.0918 - val_acc: 0.9706
Epoch 10/20
 - 21s - loss: 0.0873 - acc: 0.9727 - val_loss: 0.0774 - val_acc: 0.9763
Epoch 11/20
 - 21s - loss: 0.0820 - acc: 0.9749 - val_loss: 0.0788 - val_acc: 0.9757
Epoch 12/20
 - 21s - loss: 0.0774 - acc: 0.9764 - val_loss: 0.0710 - val_acc: 0.9767
Epoch 13/20
 - 20s - loss: 0.0724 - acc: 0.9775 - val_loss: 0.0716 - val_acc: 0.9784
Epoch 14/20
 - 20s - loss: 0.0689 - acc: 0.9790 - val_loss: 0.0753 - val_acc: 0.9761
Epoch 15/20
 - 20s - loss: 0.0652 - acc: 0.9800 - val_loss: 0.0610 - val_acc: 0.9796
Epoch 16/20
 - 22s - loss: 0.0624 - acc: 0.9805 - val_loss: 0.0611 - val_acc: 0.9806
Epoch 17/20
 - 21s - loss: 0.0602 - acc: 0.9817 - val_loss: 0.0590 - val_acc: 0.9825
Epoch 18/20
 - 20s - loss: 0.0581 - acc: 0.9821 - val_loss: 0.0634 - val_acc: 0.9807
Epoch 19/20
 - 21s - loss: 0.0553 - acc: 0.9831 - val_loss: 0.0555 - val_acc: 0.9820
Epoch 20/20
 - 19s - loss: 0.0536 - acc: 0.9837 - val_loss: 0.0547 - val_acc: 0.9815
[INFO] Salvando modelo treinado ...
[INFO] tempo de execução da CNN: 406.54 s
[INFO] avaliando a CNN...
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.99      0.97      0.98      1032
           3       0.98      0.99      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.99      0.98       892
           6       0.99      0.98      0.99       958
           7       0.97      0.99      0.98      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.98      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

[INFO] Summary: 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       
_________________________________________________________________
activation_1 (Activation)    (None, 28, 28, 6)         0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 6)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      
_________________________________________________________________
activation_2 (Activation)    (None, 10, 10, 16)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 16)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 400)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 120)               48120     
_________________________________________________________________
activation_3 (Activation)    (None, 120)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 84)                10164     
_________________________________________________________________
activation_4 (Activation)    (None, 84)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                850       
_________________________________________________________________
activation_5 (Activation)    (None, 10)                0         
=================================================================
Total params: 61,706
Trainable params: 61,706
Non-trainable params: 0
_________________________________________________________________

   32/10000 [..............................] - ETA: 1s
  288/10000 [..............................] - ETA: 1s
  512/10000 [>.............................] - ETA: 2s
  672/10000 [=>............................] - ETA: 2s
  800/10000 [=>............................] - ETA: 2s
  928/10000 [=>............................] - ETA: 2s
 1056/10000 [==>...........................] - ETA: 2s
 1216/10000 [==>...........................] - ETA: 2s
 1376/10000 [===>..........................] - ETA: 2s
 1536/10000 [===>..........................] - ETA: 2s
 1664/10000 [===>..........................] - ETA: 2s
 1792/10000 [====>.........................] - ETA: 2s
 1920/10000 [====>.........................] - ETA: 2s
 2080/10000 [=====>........................] - ETA: 2s
 2240/10000 [=====>........................] - ETA: 2s
 2400/10000 [======>.......................] - ETA: 2s
 2560/10000 [======>.......................] - ETA: 2s
 2656/10000 [======>.......................] - ETA: 2s
 2784/10000 [=======>......................] - ETA: 2s
 2912/10000 [=======>......................] - ETA: 2s
 3040/10000 [========>.....................] - ETA: 2s
 3168/10000 [========>.....................] - ETA: 2s
 3328/10000 [========>.....................] - ETA: 2s
 3488/10000 [=========>....................] - ETA: 2s
 3616/10000 [=========>....................] - ETA: 2s
 3744/10000 [==========>...................] - ETA: 2s
 3872/10000 [==========>...................] - ETA: 2s
 4000/10000 [===========>..................] - ETA: 2s
 4128/10000 [===========>..................] - ETA: 2s
 4256/10000 [===========>..................] - ETA: 2s
 4384/10000 [============>.................] - ETA: 2s
 4512/10000 [============>.................] - ETA: 2s
 4640/10000 [============>.................] - ETA: 2s
 4768/10000 [=============>................] - ETA: 2s
 4896/10000 [=============>................] - ETA: 2s
 5024/10000 [==============>...............] - ETA: 1s
 5152/10000 [==============>...............] - ETA: 1s
 5280/10000 [==============>...............] - ETA: 1s
 5408/10000 [===============>..............] - ETA: 1s
 5536/10000 [===============>..............] - ETA: 1s
 5664/10000 [===============>..............] - ETA: 1s
 5792/10000 [================>.............] - ETA: 1s
 5920/10000 [================>.............] - ETA: 1s
 6048/10000 [=================>............] - ETA: 1s
 6144/10000 [=================>............] - ETA: 1s
 6240/10000 [=================>............] - ETA: 1s
 6368/10000 [==================>...........] - ETA: 1s
 6496/10000 [==================>...........] - ETA: 1s
 6624/10000 [==================>...........] - ETA: 1s
 6752/10000 [===================>..........] - ETA: 1s
 6880/10000 [===================>..........] - ETA: 1s
 7008/10000 [====================>.........] - ETA: 1s
 7136/10000 [====================>.........] - ETA: 1s
 7264/10000 [====================>.........] - ETA: 1s
 7392/10000 [=====================>........] - ETA: 1s
 7488/10000 [=====================>........] - ETA: 1s
 7584/10000 [=====================>........] - ETA: 1s
 7680/10000 [======================>.......] - ETA: 0s
 7808/10000 [======================>.......] - ETA: 0s
 7936/10000 [======================>.......] - ETA: 0s
 8064/10000 [=======================>......] - ETA: 0s
 8192/10000 [=======================>......] - ETA: 0s
 8320/10000 [=======================>......] - ETA: 0s
 8448/10000 [========================>.....] - ETA: 0s
 8576/10000 [========================>.....] - ETA: 0s
 8704/10000 [=========================>....] - ETA: 0s
 8832/10000 [=========================>....] - ETA: 0s
 8960/10000 [=========================>....] - ETA: 0s
 9088/10000 [==========================>...] - ETA: 0s
 9216/10000 [==========================>...] - ETA: 0s
 9344/10000 [===========================>..] - ETA: 0s
 9440/10000 [===========================>..] - ETA: 0s
 9536/10000 [===========================>..] - ETA: 0s
 9632/10000 [===========================>..] - ETA: 0s
 9728/10000 [============================>.] - ETA: 0s
 9824/10000 [============================>.] - ETA: 0s
 9952/10000 [============================>.] - ETA: 0s
10000/10000 [==============================] - 4s 432us/step
[INFO] Accuracy: 98.15% | Loss: 0.05468
[INFO] Plot loss e accuracy para os datasets 'train' e 'test'
[INFO] Gerando imagem do modelo de camadas da CNN

[INFO] Finalizando ... 
